<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns#">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>Estimating Mutual Information in Bayesian Neural Networks &middot; David Blitz</title>
        <meta name="description" content="Let&rsquo;s consider a Bayesian Neural Network, where we consider the hidden layers as random variables, \(Z_i\). We also consider the input, \(X\), and the learning task, \(Y\), as random variables. Our goal is to estimate the mutual information between the input and the layers - \(I(X, Z_i)\) - as well as between the layers and the task - \(I(Z_i, Y)\). For this, we will make use of the probabilistic forward propagation approximation, as introduced [in the PBP paper].">
        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="generator" content="Hugo 0.98.0" />
        <meta name="robots" content="index,follow">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta property="og:title" content="Estimating Mutual Information in Bayesian Neural Networks">
<meta property="og:description" content="Let&rsquo;s consider a Bayesian Neural Network, where we consider the hidden layers as random variables, \(Z_i\). We also consider the input, \(X\), and the learning task, \(Y\), as random variables. Our goal is to estimate the mutual information between the input and the layers - \(I(X, Z_i)\) - as well as between the layers and the task - \(I(Z_i, Y)\). For this, we will make use of the probabilistic forward propagation approximation, as introduced [in the PBP paper].">
<meta property="og:type" content="article">
<meta property="og:url" content="https://davidblitz.github.io/2019/02/18/estimating-mutual-information-in-bnn/">
        <link rel="stylesheet" href="https://davidblitz.github.io/dist/styles.css">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,400,600,700,300&subset=latin,cyrillic-ext,latin-ext,cyrillic">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
        
        
        
    </head>
    <body>
        

        <div id="wrapper">
            <header class="site-header">
                <div class="container">
                    <div class="site-title-wrapper">
                        
                            <h1 class="site-title">
                                <a title="BlitzBlog" href="https://davidblitz.github.io/">BlitzBlog</a>
                            </h1>
                        
                        <a class="button-square" href="https://davidblitz.github.io/index.xml"><i class="fa fa-rss"></i></a>
                        
                        
                        
                            <a class="button-square button-social hint--top" data-hint="Github" title="Github" href="https://github.com/davidblitz">
                                <i class="fa fa-github-alt"></i>
                            </a>
                        
                        
                        
                        
                        
                    </div>

                    <ul class="site-nav">
                        
                    </ul>
                </div>
            </header>

            <div id="container">


<div class="container">
    <article class="post-container" itemscope="" itemtype="http://schema.org/BlogPosting">
        <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Estimating Mutual Information in Bayesian Neural Networks</h1>
    
    <p class="post-date post-line">
        <span>Published <time datetime="2019-02-18" itemprop="datePublished">Mon, Feb 18, 2019</time></span>
        <span>by</span>
        <span itemscope="" itemprop="author" itemtype="https://schema.org/Person">
            <span itemprop="name">
                <a href="https://github.com/davidblitz" itemprop="url" rel="author">David Blitz</a>
            </span>
        </span>
    </p>
    
</header>

        <div class="post-content clearfix" itemprop="articleBody">
    

    <p>Let&rsquo;s consider a Bayesian Neural Network, where we consider the hidden layers as random variables, \(Z_i\).
We also consider the input, \(X\), and the learning task, \(Y\), as random variables.
Our goal is to estimate the mutual information between the input and the layers - \(I(X, Z_i)\) -
as well as between the layers and the task - \(I(Z_i, Y)\).
For this, we will make use of the probabilistic forward propagation approximation, as introduced [in the PBP paper].</p>
<h1 id="estimating-ix-z_i">Estimating \(I(X, Z_i)\)</h1>
<p>We have
$$
I(X, Z_i) = H(Z_i) - H(Z_i | X).
$$
We can estimate each of the two entropy terms on the RHS with help of PFP:</p>
<ul>
<li>
<p>\(H(Z_i)\) can just be approximated by taking the entropy of the forward propagated distribution of \(X\). This distribution we approximate in turn by a multivariate gaussian.</p>
</li>
<li>
<p>for the conditional entropy we have:
$$
H(Z_i | X) = \mathbb{E}_x [H(Z_i | x)] = \sum_x p(x) \int p(Z_i | x) \log p(Z_i | x) dx
$$
The PFP approximation results in
$$
p(Z_i | x) \approx \mathcal{N}(Z_i | m^{i}(x), \Sigma^{i}(x) ).
$$
Using the formula for the entropy of a gaussian, we get:
$$
H(Z_i | X) = \sum_x \frac{1}{N} \frac{1}{2} \log(2 \pi e \Sigma^{i}(x)) .
$$
Notice, that this is independent of the mean of the PFP approximation.</p>
</li>
</ul>
<h1 id="estimating-iz_i-y">Estimating \(I(Z_i, Y)\)</h1>
<p>Again, we express the mutual information with entropies:
$$
I(Z_i, Y) = H(Y) - H(Y | Z_i).
$$</p>
<ul>
<li>the first term stays constant over training, so we can just ignore it or estimate it by approximating the distribution of \(Y\) by a gaussian</li>
<li>the conditional entropy is more tricky:
$$
H(Y | Z_i) = \sum_y \int p(y , Z_i) \log p(y | Z_i) dZ_i
$$
$$
= \sum_x \sum_y \int p(y, x, Z_i) \log p(y | Z_i) dZ_i
$$
$$
= \sum_x \sum_y p(x, y) \int p(Z_i | x) \log p(y | Z_i),
$$</li>
</ul>
<p>where we have used the independence of \(Z_i\) and \(Y\).
Now, we can approximate \( p(Z_i | x) \) by a Gaussian via PFP. In order, to integrate, we sampling \(z_i^1, \dots, z_i^S\) from this Gaussian, approximate
\( p(y | z_i^s) \) for each \(1 \leq s \leq S\) via PFP and finally compute
$$
\sum_s \frac{1}{S} \log p(y | z_i^s)
$$.</p>

</div>

        <footer class="post-footer clearfix">
    

    <div class="share">
        
            <a class="icon-twitter" href="https://twitter.com/share?text=Estimating%20Mutual%20Information%20in%20Bayesian%20Neural%20Networks&url=https%3a%2f%2fdavidblitz.github.io%2f2019%2f02%2f18%2festimating-mutual-information-in-bnn%2f"
                onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fa fa-twitter"></i>
                <span class="hidden">Twitter</span>
            </a>
        

        
            <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fdavidblitz.github.io%2f2019%2f02%2f18%2festimating-mutual-information-in-bnn%2f"
                onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                <i class="fa fa-facebook"></i>
                <span class="hidden">Facebook</span>
            </a>
        

        
            <a class="icon-google-plus" href="https://plus.google.com/share?url=https%3a%2f%2fdavidblitz.github.io%2f2019%2f02%2f18%2festimating-mutual-information-in-bnn%2f"
              onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
              <i class="fa fa-google-plus"></i>
                <span class="hidden">Google+</span>
            </a>
        
        
    </div>
</footer>

        
    </article>
</div>

            </div>
        </div>

        <footer class="footer">
            <div class="container">
                <div class="site-title-wrapper">
                    <h1 class="site-title">
                        <a title="BlitzBlog" href="https://davidblitz.github.io/">BlitzBlog</a>
                    </h1>
                    <a class="button-square button-jump-top js-jump-top" href="#">
                        <i class="fa fa-angle-up"></i>
                    </a>
                </div>

                <p class="footer-copyright">
                    <span>&copy; 2021 / Powered by <a href="https://gohugo.io/">Hugo</a></span>
                </p>
                <p class="footer-copyright">
                    <span><a href="https://github.com/roryg/ghostwriter">Ghostwriter theme</a> By <a href="http://jollygoodthemes.com">JollyGoodThemes</a></span>
                    <span>/ <a href="https://github.com/jbub/ghostwriter">Ported</a> to Hugo By <a href="https://github.com/jbub">jbub</a></span>
                </p>
            </div>
        </footer>

        <script src="https://davidblitz.github.io/js/jquery-1.11.3.min.js"></script>
        <script src="https://davidblitz.github.io/js/jquery.fitvids.js"></script>
        
        
            <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        
        
        <script src="https://davidblitz.github.io/js/scripts.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
    </body>
</html>

